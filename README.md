# decision-tree

<h1>What is Decision Tree? </h1>
Decision Tree builds on the classification or regression models in the form of the tree structure. It utilizes an <i>if-then rule</i> which is mutually exclusive and exhaustive for classification. The rules are learned sequentially using the training data one at a time.

<h3>Example:</h3>
An example of a personal decision to use a decision tree for may be deciding whether or not you want to enter into a lawsuit with someone, and your chances of getting a judgment in your favor. Alternatively, you can map out what would happen if the lawsuit got extended, and what would happen in the case of a win or a loss for your side, including the legal fees or potential payoff for each decision.


<h3><b>Pros</b></h3>
1.Visual and systematic approach to breaking down decision making<br>
2.Clearly outlines the long-term impacts of making certain decisions<br>
3.Decision trees can also express trade-offs and probabilities<br>

<h3><b>Cons</b></h3>
1.Over-complication of a decision can lead to analysis paralysis<br>
2.Decision trees can be overly complex with too many pathways<br>
3.Linked outcomes and uncertainty are hard to represent visually<br>


The datasets I used here are: <b> iris dataset, </b>
                             <b> boston dataset</b>
                             
The libraries I used are: <b> Matplotlib, </b>
                          <b> Scikit-learn, </b>
                          <b> Dtreeviz </b>

